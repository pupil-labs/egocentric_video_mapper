{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd\n",
    "import pupil_labs.video as plv\n",
    "from utils import VideoHandler, write_action_timestamp_csv\n",
    "from optic_flow import OpticFlowCalculatorLK\n",
    "from sync_videos import OffsetCalculator\n",
    "from gaze_mapper import ActionCameraGazeMapper \n",
    "from video_renderer import save_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give a the path to the directory of the uncompressed Scene Video + Timeseries download from Cloud and its corresponding Action Camera recording ( please make sure that both videos have the same orientation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neon_timeseries_path='/users/sof/video_examples/second_video/2024-05-23_16-47-35-a666ea62'\n",
    "neon_vid_path='/users/sof/video_examples/second_video/2024-05-23_16-47-35-a666ea62/e69049ea_0.0-42.986.mp4'\n",
    "action_vid_path='/users/sof/video_examples/second_video/20240523_171941_000.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an output directory where the optic flow signal, gazes mapped to the action camera and the video visualization will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir='/users/sof/action_map_experiments/second_video'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Obtain Optic Flow\n",
    "\n",
    "There are two different optic_flow classes: one using Lucas-Kanade method (sparse-gridlike optic flow)and another one using  Gunnar Farneback method (dense, pixel-wise optic flow).\n",
    "\n",
    "Lukas Kanade is way faster than the Gunnar Farneback Method, so this notebook will run with this method (For a 2min video it takes around ~3min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_of = OpticFlowCalculatorLK(video_dir=action_vid_path)\n",
    "neon_of = OpticFlowCalculatorLK(video_dir=neon_vid_path)\n",
    "\n",
    "neon_result = neon_of.get_all_optic_flow()\n",
    "action_result = action_of.get_all_optic_flow()\n",
    "\n",
    "plt.figure(figsize=(25,5)) \n",
    "plt.plot(neon_result['end'].values,np.rad2deg(neon_result['angle'].values),label='neon')\n",
    "plt.plot(action_result['end'].values,np.rad2deg(action_result['angle'].values),label='action')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the write_to_csv method, the optic flow results are saved to a csv file in a user indicated address. The csv file will contain the following columns:\n",
    "- start: the start frame timestamp of the optic flow calculation\n",
    "- end: the end frame timestamp of the optic flow calculation\n",
    "- angle\n",
    "- avg_displacement_x\n",
    "- avg_displacement_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optic_flow_output_dir = Path(output_dir, 'optic_flow')\n",
    "optic_flow_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "action_of_csv=Path(optic_flow_output_dir, 'action_lk_of.csv')\n",
    "neon_of_csv=Path(optic_flow_output_dir, 'neon_lk_of.csv')\n",
    "action_of.write_to_csv(action_of_csv)\n",
    "neon_of.write_to_csv(neon_of_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Estimate time offset between videos\n",
    "\n",
    "After optic flow is calculated, the OffsetCalculator class obtains the time offset of the action video with respect to the neon scene video. Optionally one can also indicate a period of time of the action (source) optic flow signal, to be matched to the whole neon (destination) signal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_calc=OffsetCalculator(source=action_result['angle'].values,source_timestamps=action_result['start'].values, destination=neon_result['angle'].values, destination_timestamps=neon_result['start'].values,resampling_frequency=500)\n",
    "t_offset, pearson_corr = offset_calc.estimate_time_offset()\n",
    "print(f'Estimated offset: {t_offset} seconds (Pearson correlation: {pearson_corr})')\n",
    "\n",
    "start,end = None,None\n",
    "idx=offset_calc._obtain_indexes(offset_calc.source_resampled_timestamps,start,end)\n",
    "x_cor,lags=offset_calc._cross_correlate(offset_calc.source_resampled[idx[0]:idx[1]])\n",
    "s_offset = lags[np.argmax(x_cor)]\n",
    "s,d=offset_calc._obtain_overlapping_signals(s_offset,offset_calc.source_resampled[idx[0]:idx[1]])\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.plot(d,label='Neon')\n",
    "plt.plot(s, label='Action')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also select a time interval in the action video to estimate the delay. Try modifying the values in start_action and end_action. The printed estimated offset must be similar. If the visualization in the graph dpesnt seem to overlap nicely, try picking other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_action = 3\n",
    "end_action = 20\n",
    "\n",
    "\n",
    "t_offset,pearson_corr = offset_calc.estimate_time_offset(source_end_time=end, source_start_time=start)\n",
    "print(f'Estimated offset: {t_offset} seconds (Pearson correlation: {pearson_corr})')\n",
    "idx=offset_calc._obtain_indexes(offset_calc.source_resampled_timestamps,start,end)\n",
    "x_cor,lags=offset_calc._cross_correlate(offset_calc.source_resampled[idx[0]:idx[1]])\n",
    "s_offset = lags[np.argmax(x_cor)]\n",
    "s,d=offset_calc._obtain_overlapping_signals(s_offset,offset_calc.source_resampled[idx[0]:idx[1]])\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.plot(d,label='Neon')\n",
    "plt.plot(s, label='Action')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Creation of action_worldtimestamps.csv\n",
    "\n",
    "Once calculated the time offset, the action_worldtimestamps.csv can be generated with the function write_worldtimestamp_csv. This function wirtes the csv to the same directory as the given world_timestamps.csv from Neon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actionVid=VideoHandler(action_vid_path)\n",
    "neon_timestamps= Path(neon_timeseries_path, 'world_timestamps.csv')\n",
    "write_action_timestamp_csv(neon_timestamps, actionVid.timestamps+t_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Map gaze data to the action video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_timestamps= neon_timestamps.replace('world_timestamps.csv','action_camera_world_timestamps.csv')\n",
    "\n",
    "neon_gaze_csv=neon_timestamps.replace('world_timestamps.csv','gaze.csv')\n",
    "\n",
    "param_lg = {'num_features':2048,'gpu_num':0}\n",
    "param_loftr = {'location':'indoor', 'gpu_num':0}\n",
    "image_matcher_loftr={'choice':'loftr','parameters':param_loftr}\n",
    "image_matcher_lg={'choice':'disk_lightglue','parameters':param_lg}\n",
    "\n",
    "image_matcher=image_matcher_loftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = ActionCameraGazeMapper(neon_gaze_csv=neon_gaze_csv,\n",
    "        neon_video_dir=neon_vid_path,\n",
    "        action_video_dir=action_vid_path,\n",
    "        neon_worldtimestamps=neon_timestamps,\n",
    "        action_worldtimestamps=action_timestamps,\n",
    "        image_matcher=image_matcher['choice'],\n",
    "        image_matcher_parameters=image_matcher['parameters'],\n",
    "        neon_opticflow_csv=neon_of_csv,\n",
    "        action_opticflow_csv=action_of_csv,\n",
    "        patch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_csv_path = Path(output_dir,f\"action_gaze_lk.csv\")\n",
    "mapper.map_gaze(saving_path=gaze_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create a video with both Neon and Action Camera "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_gaze_dict = {image_matcher['choice'].upper(): gaze_csv_path}\n",
    "rendered_video_path = Path(output_dir, f\"video_rendered/Neon_Actionrendered_{image_matcher['choice']}_lk.avi\")\n",
    "Path(rendered_video_path).parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_video(action_video_path=action_vid_path,\n",
    "        action_worldtimestamps_path=action_timestamps,\n",
    "        action_gaze_paths_dict=action_gaze_dict,\n",
    "        neon_video_path=neon_vid_path,\n",
    "        neon_worldtimestamps_path=neon_timestamps,\n",
    "        neon_gaze_path=neon_gaze_csv,\n",
    "        save_video_path=rendered_video_path)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sof_gazemapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
